{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gnKCepqHMJAt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from collections import OrderedDict, Counter\n",
        "from sklearn import tree, svm\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgICc_q9Xfqw"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EL8OZYvaMTtc"
      },
      "outputs": [],
      "source": [
        "# Read the structured HDFS log file\n",
        "struct_log = pd.read_csv('../data/HDFS_100k.log_structured.csv', engine='c', na_filter=False, memory_map=True)\n",
        "\n",
        "# Convert it into a dictionary containing a set of events happening in a block (of file system)\n",
        "# with blockId as the key and set of events as value\n",
        "data_dict = OrderedDict()\n",
        "for idx, row in struct_log.iterrows():\n",
        "    # Finding block ids in every log using regular expression\n",
        "    blkId_list = re.findall(r'(blk_-?\\d+)', row['Content'])\n",
        "    blkId_set = set(blkId_list)\n",
        "    for blk_Id in blkId_set:\n",
        "        if not blk_Id in data_dict:\n",
        "            data_dict[blk_Id] = []\n",
        "        # Creating a sequence of events happening over an HDFS block\n",
        "        data_dict[blk_Id].append(row['EventId'])\n",
        "\n",
        "# Creating the final DataFrame that we will work on\n",
        "data_df = pd.DataFrame(list(data_dict.items()), columns=['BlockId', 'EventSequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FB6J5jfCO1AS",
        "outputId": "34e25b14-9dbe-4406-af95-4c2fe454b606"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BlockId</th>\n",
              "      <th>EventSequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blk_-1608999687919862906</td>\n",
              "      <td>[E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blk_7503483334202473044</td>\n",
              "      <td>[E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blk_-3544583377289625738</td>\n",
              "      <td>[E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blk_-9073992586687739851</td>\n",
              "      <td>[E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blk_7854771516489510256</td>\n",
              "      <td>[E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    BlockId                                      EventSequence\n",
              "0  blk_-1608999687919862906  [E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...\n",
              "1   blk_7503483334202473044  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...\n",
              "2  blk_-3544583377289625738  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
              "3  blk_-9073992586687739851  [E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...\n",
              "4   blk_7854771516489510256  [E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zY9Bp1CNO_tS"
      },
      "outputs": [],
      "source": [
        "# Reading anomaly labels\n",
        "label_data = pd.read_csv('../data/anomaly_label.csv', engine='c', na_filter=False, memory_map=True)\n",
        "\n",
        "# Using BlockIds as keys\n",
        "label_data = label_data.set_index('BlockId')\n",
        "\n",
        "# Creating a new attribute Label in the data frame (dependent variable)\n",
        "label_dict = label_data['Label'].to_dict()\n",
        "data_df['Label'] = data_df['BlockId'].apply(lambda x: 1 if label_dict[x] == 'Anomaly' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IG9WoA2SQX47",
        "outputId": "455864c7-4935-4754-bbd5-23fd295103a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BlockId</th>\n",
              "      <th>EventSequence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blk_-1608999687919862906</td>\n",
              "      <td>[E5, E22, E5, E5, E11, E11, E9, E9, E11, E9, E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blk_7503483334202473044</td>\n",
              "      <td>[E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blk_-3544583377289625738</td>\n",
              "      <td>[E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blk_-9073992586687739851</td>\n",
              "      <td>[E5, E22, E5, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blk_7854771516489510256</td>\n",
              "      <td>[E5, E5, E22, E5, E11, E9, E11, E9, E11, E9, E...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    BlockId  ... Label\n",
              "0  blk_-1608999687919862906  ...     0\n",
              "1   blk_7503483334202473044  ...     0\n",
              "2  blk_-3544583377289625738  ...     1\n",
              "3  blk_-9073992586687739851  ...     0\n",
              "4   blk_7854771516489510256  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf1iOxb3XuZ0"
      },
      "source": [
        "# Splitting into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mQj4msNJQdjv"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test set {train: 70%, test: 30%}\n",
        "yValues = data_df['Label'].values\n",
        "xValues = data_df['EventSequence'].values\n",
        "\n",
        "# Splitting normal and anomalous blocks\n",
        "# Indices of normal logs\n",
        "pos_idx = yValues > 0\n",
        "x_pos = xValues[pos_idx]\n",
        "y_pos = yValues[pos_idx]\n",
        "# DataFrames with events of block with anomaly\n",
        "x_neg = xValues[~pos_idx]\n",
        "y_neg = yValues[~pos_idx]\n",
        "train_pos = int(0.7 * x_pos.shape[0])\n",
        "train_neg = int(0.7 * x_neg.shape[0])\n",
        "\n",
        "# Splitting into train and test set\n",
        "x_train = np.hstack([x_pos[0:train_pos], x_neg[0:train_neg]])\n",
        "y_train = np.hstack([y_pos[0:train_pos], y_neg[0:train_neg]])\n",
        "x_test = np.hstack([x_pos[train_pos:], x_neg[train_neg:]])\n",
        "y_test = np.hstack([y_pos[train_pos:], y_neg[train_neg:]])\n",
        "\n",
        "# Random shuffle since DataFrame has normal logs and anomalous logs separated\n",
        "indexes = shuffle(np.arange(x_train.shape[0]))\n",
        "x_train = x_train[indexes]\n",
        "y_train = y_train[indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYfbTjgKWOwd",
        "outputId": "ba5f9d29-78f5-4b15-a951-8773097f232d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[list(['E5', 'E22', 'E5', 'E5', 'E11', 'E11', 'E9', 'E9', 'E11', 'E9', 'E26', 'E26', 'E26'])\n",
            " list(['E22', 'E5', 'E5', 'E5', 'E26', 'E26', 'E11', 'E9', 'E11', 'E9', 'E26', 'E11', 'E9'])\n",
            " list(['E22', 'E5', 'E5', 'E5', 'E11', 'E9', 'E11', 'E9', 'E26', 'E26', 'E26', 'E11', 'E9'])\n",
            " ...\n",
            " list(['E5', 'E22', 'E5', 'E5', 'E11', 'E9', 'E11', 'E9', 'E11', 'E9', 'E26', 'E26', 'E26', 'E2', 'E2'])\n",
            " list(['E22', 'E5', 'E5', 'E5', 'E26', 'E26', 'E26', 'E11', 'E9', 'E11', 'E9', 'E11', 'E9', 'E2'])\n",
            " list(['E22', 'E5', 'E5', 'E5', 'E26', 'E26', 'E26', 'E11', 'E9', 'E11', 'E9', 'E11', 'E9'])] [0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOxU5JFkX5ra"
      },
      "source": [
        "# Preprocessing and Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueQ2AmoCX8iW",
        "outputId": "e4c5941d-e96a-4cd8-924a-ad66d0ece51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: 5557-by-16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Transforming x_train into Tf-Idf vectors\n",
        "X_counts = []\n",
        "# For every block, count each event\n",
        "for i in range(x_train.shape[0]):\n",
        "    event_counts = Counter(x_train[i])\n",
        "    X_counts.append(event_counts)\n",
        "\n",
        "# Create a DataFrame with event count dictionary\n",
        "X_df = pd.DataFrame(X_counts)\n",
        "# Fill events that did not occur on the block with 0\n",
        "X_df = X_df.fillna(0)\n",
        "events = X_df.columns\n",
        "X = X_df.values\n",
        "\n",
        "# Vectorizing using TF-IDF vectors\n",
        "num_instance, num_event = X.shape\n",
        "df_vec = np.sum(X > 0, axis=0)\n",
        "idf_vec = np.log(num_instance / (df_vec + 1e-8))\n",
        "x_train = X * np.tile(idf_vec, (num_instance, 1)) \n",
        "\n",
        "print('Train data shape: {}-by-{}\\n'.format(x_train.shape[0], x_train.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixx-CEZkaHpU",
        "outputId": "2ac90b01-205d-4406-e9ce-c828c4d85f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data shape: 2383-by-16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Similar steps followed for Testing set\n",
        "X_counts = []\n",
        "for i in range(x_test.shape[0]):\n",
        "    event_counts = Counter(x_test[i])\n",
        "    X_counts.append(event_counts)\n",
        "X_df = pd.DataFrame(X_counts)\n",
        "X_df = X_df.fillna(0)\n",
        "\n",
        "empty_events = set(events) - set(X_df.columns)\n",
        "for event in empty_events:\n",
        "    X_df[event] = [0] * len(X_df)\n",
        "X = X_df[events].values\n",
        "\n",
        "num_instance, num_event = X.shape\n",
        "x_test = X * np.tile(idf_vec, (num_instance, 1)) \n",
        "\n",
        "\n",
        "print('Test data shape: {}-by-{}\\n'.format(x_test.shape[0], x_test.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZluvEjnwEeF",
        "outputId": "a3cfe234-c1c4-46db-e0fb-05822f6c5912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-7.19824200e-12 -1.79956050e-12  4.73393336e-02 ...  7.01337576e+00\n",
            "   7.23651931e+00  0.00000000e+00]\n",
            " [-7.19824200e-12 -1.79956050e-12  4.73393336e-02 ...  7.01337576e+00\n",
            "   7.23651931e+00  0.00000000e+00]\n",
            " [-7.19824200e-12 -1.79956050e-12  4.73393336e-02 ...  7.01337576e+00\n",
            "   7.23651931e+00  0.00000000e+00]\n",
            " ...\n",
            " [-5.39868150e-12 -1.79956050e-12  4.73393336e-02 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-5.39868150e-12 -1.79956050e-12  4.73393336e-02 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-5.39868150e-12 -1.79956050e-12  4.73393336e-02 ...  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERco1y1Xkelx"
      },
      "source": [
        "# Decision Tree Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvbT3V0YkW8c",
        "outputId": "6668d6e1-9036-4e6e-98d1-fccfd2fe7267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.972, recall: 0.372, F1-measure: 0.538\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier = tree.DecisionTreeClassifier()\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(X)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print('Precision: {:.3f}, recall: {:.3f}, F1-measure: {:.3f}\\n'.format(precision, recall, f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaftjQSFvrLv"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-E3pkoqvu-H",
        "outputId": "7a805e8f-33d1-4b35-d38a-297d840a6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.953, recall: 0.436, F1-measure: 0.599\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print('Precision: {:.3f}, recall: {:.3f}, F1-measure: {:.3f}\\n'.format(precision, recall, f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhQlVAlg4Rdc"
      },
      "source": [
        "# SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1K8eoM64Q-E",
        "outputId": "977ee1bb-87e0-4ed7-8696-f5d7b2e39095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.953, recall: 0.436, F1-measure: 0.599\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "classifier = svm.LinearSVC()\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print('Precision: {:.3f}, recall: {:.3f}, F1-measure: {:.3f}\\n'.format(precision, recall, f1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "detect-o-maly.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
